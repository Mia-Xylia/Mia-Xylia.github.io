



<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="https://fastly.jsdelivr.net/gh/Mia-Xylia/Mia-Xylia.github.io@latest/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="https://fastly.jsdelivr.net/gh/Mia-Xylia/Mia-Xylia.github.io@latest/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="" href="http://example.com/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="" href="http://example.com/atom.xml" />
<link rel="alternate" type="application/json" title="" href="http://example.com/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://fastly.jsdelivr.net/gh/Mia-Xylia/Mia-Xylia.github.io@latest/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="笔记,pytorch基础" />


<link rel="canonical" href="http://example.com/2025/03/26/computer-science/python/pytorch3/">



  <title>
笔记：PyTorch(3) - Python - 计算机科学 |
鱼塘 = </title>
<meta name="generator" content="Hexo 7.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">笔记：PyTorch(3)
  </h1>
  
<div class="meta">
  <span class="item" title="创建时间：2025-03-26 00:00:00">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">发表于</span>
    <time itemprop="dateCreated datePublished" datetime="2025-03-26T00:00:00+08:00">2025-03-26</time>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="切换导航栏">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">鱼塘</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
          <img src="https://fastly.jsdelivr.net/gh/Mia-Xylia/Mia-Xylia.github.io@latest/assets/wallpaper-2572384.jpg">
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">首页</a></span><i class="ic i-angle-right"></i>
<span  itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/computer-science/" itemprop="item" rel="index" title="分类于 计算机科学"><span itemprop="name">计算机科学</span></a>
<meta itemprop="position" content="1" /></span>
<i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/computer-science/python/" itemprop="item" rel="index" title="分类于 Python"><span itemprop="name">Python</span></a>
<meta itemprop="position" content="2" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN">
  <link itemprop="mainEntityOfPage" href="http://example.com/2025/03/26/computer-science/python/pytorch3/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="https://fastly.jsdelivr.net/gh/Mia-Xylia/Mia-Xylia.github.io@latest/images/avatar.jpg">
    <meta itemprop="name" content="Xylia">
    <meta itemprop="description" content=", ">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <h1 id="loss-functions"><a class="markdownIt-Anchor" href="#loss-functions">#</a> Loss Functions</h1>
<ul>
<li>
<p>Loss<br>
target = 1,2,5<br>
output = 1,2,3<br>
Loss = target - output<br>
1. 计算实际输出和目标之间的差距<br>
 2. 为我们更新输出提供一定的依据（反向传播）</p>
</li>
<li>
<p>L1loss<br>
L1loss = (0+0+2^2)/3</p>
</li>
</ul>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```python</span> <span class="string">L1loss</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.nn</span> <span class="string">import</span> <span class="string">L1Loss</span></span><br><span class="line"></span><br><span class="line"><span class="string">input</span> <span class="string">=</span> <span class="string">torch.tensor([1,2,3],dtype=torch.float32)</span></span><br><span class="line"><span class="string">target</span> <span class="string">=</span> <span class="string">torch.tensor([1,2,5])</span></span><br><span class="line"></span><br><span class="line"><span class="string">input</span> <span class="string">=</span> <span class="string">torch.reshape(input,</span> <span class="string">(1,1,1,3))</span></span><br><span class="line"><span class="string">target</span> <span class="string">=</span> <span class="string">torch.reshape(target,</span> <span class="string">(1,1,1,3))</span></span><br><span class="line"></span><br><span class="line"><span class="string">loss</span> <span class="string">=</span> <span class="string">L1Loss(reduction=&#x27;sum&#x27;)</span></span><br><span class="line"><span class="string">result</span> <span class="string">=</span> <span class="string">loss(input,</span> <span class="string">target)</span></span><br><span class="line"><span class="string">print(result)</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<ul>
<li>MSELoss<br>
MSELoss = (0+0+2)/3</li>
</ul>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```python</span> <span class="string">mes</span></span><br><span class="line"><span class="string">loss_mae</span> <span class="string">=</span> <span class="string">nn.MSELoss()</span></span><br><span class="line"><span class="string">result_mse</span> <span class="string">=</span> <span class="string">loss_mae(input,</span> <span class="string">target)</span></span><br><span class="line"></span><br><span class="line"><span class="string">print(result_mse)</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<ul>
<li>CrossEntropyLoss</li>
</ul>
<p>person,dog,cat[0,1,2]<br>
input = img[dog]<br>
nn :<br>
output = [0.1,0.2,0.3]      x<br>
target = [1]    class<br>
loss(x,class) = -0.2 +ln(exp(0.1)+exp(0.2),exp(0.3))</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```python</span>  <span class="string">验证</span></span><br><span class="line"><span class="string">x</span> <span class="string">=</span> <span class="string">torch.tensor([0.1,0.2,0.3])</span></span><br><span class="line"><span class="string">y</span> <span class="string">=</span> <span class="string">torch.tensor([1])</span></span><br><span class="line"><span class="string">x</span> <span class="string">=</span> <span class="string">torch.reshape(x,</span> <span class="string">(1,3))</span></span><br><span class="line"><span class="string">loss_cross</span> <span class="string">=</span> <span class="string">nn.CrossEntropyLoss()</span></span><br><span class="line"><span class="string">result_cross</span> <span class="string">=</span> <span class="string">loss_cross(x,y)</span></span><br><span class="line"><span class="string">print(result_cross)</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```python</span> <span class="string">CrossEntropyLoss+网络</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch</span> <span class="string">import</span> <span class="string">nn</span></span><br><span class="line"><span class="string">import</span> <span class="string">torchvision</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.nn</span> <span class="string">import</span> <span class="string">Conv2d,MaxPool2d,Flatten,Linear</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.utils.data</span> <span class="string">import</span> <span class="string">DataLoader</span></span><br><span class="line"></span><br><span class="line"><span class="string">dataset</span> <span class="string">=</span> <span class="string">torchvision.datasets.CIFAR10(&quot;./data&quot;,</span> <span class="string">train=False,</span> <span class="string">download=True,</span></span><br><span class="line">                                       <span class="string">transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"><span class="string">dataloader</span> <span class="string">=</span> <span class="string">DataLoader(dataset,</span> <span class="string">batch_size=1)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">class Xylia(nn.Module):</span></span><br><span class="line">    <span class="attr">def __init__(self):</span></span><br><span class="line">        <span class="string">super(Xylia,</span> <span class="string">self).__init__()</span></span><br><span class="line">        <span class="string">self.model</span> <span class="string">=</span> <span class="string">nn.Sequential(</span></span><br><span class="line">            <span class="string">Conv2d(3,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,padding=2),</span></span><br><span class="line">            <span class="string">MaxPool2d(2),</span></span><br><span class="line">            <span class="string">Conv2d(32,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,padding=2),</span></span><br><span class="line">            <span class="string">MaxPool2d(2),</span></span><br><span class="line">            <span class="string">Conv2d(32,</span> <span class="number">64</span><span class="string">,</span> <span class="string">kernel_size=5,padding=2),</span></span><br><span class="line">            <span class="string">MaxPool2d(2),</span></span><br><span class="line">            <span class="string">Flatten(),</span></span><br><span class="line">            <span class="string">Linear(1024,</span> <span class="number">64</span><span class="string">),</span></span><br><span class="line">            <span class="string">Linear(64,</span> <span class="number">10</span><span class="string">)</span></span><br><span class="line">        <span class="string">)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">def</span> <span class="string">forward(self,</span> <span class="attr">x):</span></span><br><span class="line">        <span class="string">x</span> <span class="string">=</span> <span class="string">self.model(x)</span></span><br><span class="line">        <span class="string">return</span> <span class="string">x</span></span><br><span class="line"></span><br><span class="line"><span class="string">loss</span> <span class="string">=</span> <span class="string">nn.CrossEntropyLoss()</span></span><br><span class="line"><span class="string">xylia</span> <span class="string">=</span> <span class="string">Xylia()</span></span><br><span class="line"><span class="attr">for data in dataloader:</span></span><br><span class="line">    <span class="string">imgs,targets</span> <span class="string">=</span> <span class="string">data</span></span><br><span class="line">    <span class="string">outputs</span> <span class="string">=</span> <span class="string">xylia(imgs)</span></span><br><span class="line">    <span class="comment"># print(outputs)</span></span><br><span class="line">    <span class="comment"># print(targets)</span></span><br><span class="line">    <span class="string">cross_loss</span> <span class="string">=</span> <span class="string">loss(outputs,targets)</span></span><br><span class="line">    <span class="string">print(cross_loss)</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<h1 id="优化器"><a class="markdownIt-Anchor" href="#优化器">#</a> 优化器</h1>
<p><span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzLzEuOC4xL29wdGltLmh0bWw=">torch.optim</span><br>
Lr = learning rate</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch</span> <span class="string">import</span> <span class="string">nn</span></span><br><span class="line"><span class="string">import</span> <span class="string">torchvision</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.nn</span> <span class="string">import</span> <span class="string">Conv2d,MaxPool2d,Flatten,Linear</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.utils.data</span> <span class="string">import</span> <span class="string">DataLoader</span></span><br><span class="line"></span><br><span class="line"><span class="string">dataset</span> <span class="string">=</span> <span class="string">torchvision.datasets.CIFAR10(&quot;./data&quot;,</span> <span class="string">train=False,</span> <span class="string">download=True,</span></span><br><span class="line">                                       <span class="string">transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"><span class="string">dataloader</span> <span class="string">=</span> <span class="string">DataLoader(dataset,</span> <span class="string">batch_size=1)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">class Xylia(nn.Module):</span></span><br><span class="line">    <span class="attr">def __init__(self):</span></span><br><span class="line">        <span class="string">super(Xylia,</span> <span class="string">self).__init__()</span></span><br><span class="line">        <span class="string">self.model</span> <span class="string">=</span> <span class="string">nn.Sequential(</span></span><br><span class="line">            <span class="string">Conv2d(3,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,padding=2),</span></span><br><span class="line">            <span class="string">MaxPool2d(2),</span></span><br><span class="line">            <span class="string">Conv2d(32,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,padding=2),</span></span><br><span class="line">            <span class="string">MaxPool2d(2),</span></span><br><span class="line">            <span class="string">Conv2d(32,</span> <span class="number">64</span><span class="string">,</span> <span class="string">kernel_size=5,padding=2),</span></span><br><span class="line">            <span class="string">MaxPool2d(2),</span></span><br><span class="line">            <span class="string">Flatten(),</span></span><br><span class="line">            <span class="string">Linear(1024,</span> <span class="number">64</span><span class="string">),</span></span><br><span class="line">            <span class="string">Linear(64,</span> <span class="number">10</span><span class="string">)</span></span><br><span class="line">        <span class="string">)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">def</span> <span class="string">forward(self,</span> <span class="attr">x):</span></span><br><span class="line">        <span class="string">x</span> <span class="string">=</span> <span class="string">self.model(x)</span></span><br><span class="line">        <span class="string">return</span> <span class="string">x</span></span><br><span class="line"></span><br><span class="line"><span class="string">loss</span> <span class="string">=</span> <span class="string">nn.CrossEntropyLoss()</span></span><br><span class="line"><span class="string">xylia</span> <span class="string">=</span> <span class="string">Xylia()</span></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line"><span class="string">optimizer</span> <span class="string">=</span> <span class="string">torch.optim.SGD(xylia.parameters(),</span> <span class="string">lr=0.01)</span></span><br><span class="line"><span class="comment"># 运行20轮</span></span><br><span class="line"><span class="attr">for epoch in range(20):</span></span><br><span class="line">    <span class="string">runing_loss</span> <span class="string">=</span> <span class="number">0.0</span></span><br><span class="line">    <span class="attr">for data in dataloader:</span></span><br><span class="line">        <span class="string">imgs,targets</span> <span class="string">=</span> <span class="string">data</span></span><br><span class="line">        <span class="string">outputs</span> <span class="string">=</span> <span class="string">xylia(imgs)</span></span><br><span class="line">        <span class="string">result_loss</span> <span class="string">=</span> <span class="string">loss(outputs,targets)</span></span><br><span class="line">        <span class="comment"># 将优化器中对应的每一个参数清零</span></span><br><span class="line">        <span class="string">optimizer.zero_grad()</span></span><br><span class="line">        <span class="comment"># 反向传播求出每个节点的梯度</span></span><br><span class="line">        <span class="string">result_loss.backward()</span></span><br><span class="line">        <span class="string">optimizer.step()</span></span><br><span class="line">        <span class="comment"># print(result_loss)</span></span><br><span class="line">        <span class="string">runing_loss</span> <span class="string">+=</span> <span class="string">result_loss</span></span><br><span class="line"></span><br><span class="line">    <span class="string">print(runing_loss)</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<h1 id="网络模型"><a class="markdownIt-Anchor" href="#网络模型">#</a> 网络模型</h1>
<h2 id="现有网络模型的使用及修改"><a class="markdownIt-Anchor" href="#现有网络模型的使用及修改">#</a> 现有网络模型的使用及修改</h2>
<details class="success"><summary>数据集</summary><div>
<p>;;;<br>
<span class="label success">success</span></p>
<div class="links"><div class="item" title="VGG16" style="--block-color:#e9546b;"><span class="exturl image" data-url="aHR0cHM6Ly9wYW4uYmFpZHUuY29tL3MvMWVVaDl4S0F4U1RRUWkwWHlEQ1p6UHc/cHdkPXA3anc=" data-background-image="https://img.88icon.com/download/jpg/201912/20212877d98b95ae7730decb11762bac.jpg!bg"></span>
          <div class="info">
          <span class="exturl title" data-url="aHR0cHM6Ly9wYW4uYmFpZHUuY29tL3MvMWVVaDl4S0F4U1RRUWkwWHlEQ1p6UHc/cHdkPXA3anc=">VGG16</span>
          <p class="desc">密码p7jw</p>
          </div></div></div>
<p>;;;</p>
</div></details>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```python</span></span><br><span class="line"><span class="string">import</span> <span class="string">torchvision</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch</span> <span class="string">import</span> <span class="string">nn</span></span><br><span class="line"><span class="string">from</span> <span class="string">torchvision.models</span> <span class="string">import</span> <span class="string">vgg16,</span> <span class="string">VGG16_Weights</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># train_data = torchvision.datasets.ImageNet(&quot;./data&quot;,split=&#x27;train&#x27;,download= True,</span></span><br><span class="line"><span class="comment">#                                            transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置权重文件的存储路径,默认保存到以下路径的checkpoints中</span></span><br><span class="line"><span class="string">torch.hub.set_dir(&#x27;./data&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#  The parameter &#x27;pretrained&#x27; is deprecated since 0.13 and may be removed in the future, please use &#x27;weights&#x27; instead.</span></span><br><span class="line"><span class="comment"># vgg16_false = torchvision.models.vgg16(pretrained=False)</span></span><br><span class="line"><span class="comment"># vgg16_true = torchvision.models.vgg16(pretrained=True)</span></span><br><span class="line"><span class="string">vgg16_false</span> <span class="string">=</span> <span class="string">torchvision.models.vgg16(weights=None)</span></span><br><span class="line"><span class="string">vgg16_true</span> <span class="string">=</span> <span class="string">torchvision.models.vgg16(weights=VGG16_Weights.DEFAULT)</span></span><br><span class="line"><span class="comment"># print(&#x27;ok&#x27;)</span></span><br><span class="line"><span class="string">print(vgg16_true)</span></span><br><span class="line"></span><br><span class="line"><span class="string">train_data</span> <span class="string">=</span> <span class="string">torchvision.datasets.CIFAR10(&quot;./data&quot;,</span> <span class="string">train=True,</span> <span class="string">download=True,</span> <span class="string">transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 改动结构</span></span><br><span class="line"><span class="string">vgg16_true.classifier.add_module(&#x27;add_linear&#x27;,</span> <span class="string">nn.Linear(1000,</span> <span class="number">10</span><span class="string">))</span></span><br><span class="line"><span class="string">print(vgg16_true)</span></span><br><span class="line"></span><br><span class="line"><span class="string">print(vgg16_false)</span></span><br><span class="line"><span class="string">vgg16_false.classifier[6]</span> <span class="string">=</span> <span class="string">nn.Linear(4096,</span> <span class="number">10</span><span class="string">)</span></span><br><span class="line"><span class="string">print(vgg16_false)</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<h2 id="网络模型的保存与读取"><a class="markdownIt-Anchor" href="#网络模型的保存与读取">#</a> 网络模型的保存与读取</h2>
<ul>
<li>模型的保存</li>
</ul>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">import</span> <span class="string">torchvision</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch</span></span><br><span class="line"></span><br><span class="line"><span class="string">torch.hub.set_dir(&#x27;./data&#x27;)</span></span><br><span class="line"><span class="string">vgg16</span> <span class="string">=</span> <span class="string">torchvision.models.vgg16(weights=None)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式1 模型结构+模型参数</span></span><br><span class="line"><span class="string">torch.save(vgg16,&quot;vgg_method1.pth&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式2  模型参数（官方推荐）</span></span><br><span class="line"><span class="string">torch.save(vgg16.state_dict(),&quot;vgg_method2.pth&quot;)</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<ul>
<li>模型的读取</li>
</ul>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch</span></span><br><span class="line"><span class="string">import</span> <span class="string">torchvision</span></span><br><span class="line"><span class="string">from</span> <span class="string">model_save</span> <span class="string">import</span> <span class="string">vgg16</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch</span> <span class="string">import</span> <span class="string">nn</span></span><br><span class="line"><span class="string">from</span> <span class="string">model_save</span> <span class="string">import</span> <span class="string">*</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式1 -&gt; 保存方式1，加载模型</span></span><br><span class="line"></span><br><span class="line"><span class="string">model</span> <span class="string">=</span> <span class="string">torch.load(&quot;vgg_method1.pth&quot;,weights_only=False)</span></span><br><span class="line"><span class="string">print(model)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式2</span></span><br><span class="line"><span class="string">torch.hub.set_dir(&#x27;./data&#x27;)</span></span><br><span class="line"><span class="string">vgg16.load_state_dict(torch.load(&quot;vgg_method2.pth&quot;))</span></span><br><span class="line"><span class="comment"># model2 = torch.load(&quot;vgg_method2.pth&quot;,weights_only=False)</span></span><br><span class="line"><span class="string">print(vgg16)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式1陷阱</span></span><br><span class="line"><span class="attr">class Xylia(nn.Module):</span></span><br><span class="line">    <span class="attr">def __init__(self):</span></span><br><span class="line">        <span class="string">super(Xylia,self).__init__()</span></span><br><span class="line">        <span class="string">self.conv1</span> <span class="string">=</span> <span class="string">nn.Conv2d(3,64,kernel_size=3)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">def</span> <span class="string">forward(self,x):</span></span><br><span class="line">        <span class="string">x</span> <span class="string">=</span> <span class="string">self.conv1(x)</span></span><br><span class="line">        <span class="string">return</span> <span class="string">x</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># xylia = Xylia()</span></span><br><span class="line"><span class="comment"># model = torch.save(xylia,&quot;xylia_method1.pth&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 陷阱1</span></span><br><span class="line"><span class="string">model</span> <span class="string">=</span> <span class="string">torch.load(&quot;xylia_method1.pth&quot;,weights_only=False)</span></span><br><span class="line"><span class="string">print(model)</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<h2 id="完整的模型训练套路"><a class="markdownIt-Anchor" href="#完整的模型训练套路">#</a> 完整的模型训练套路</h2>
<ul>
<li>.item()</li>
</ul>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch</span></span><br><span class="line"><span class="string">a</span> <span class="string">=</span> <span class="string">torch.tensor(5)</span></span><br><span class="line"><span class="string">print(a)</span></span><br><span class="line"><span class="string">print(a.item())</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<ul>
<li>.argmax</li>
</ul>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch</span></span><br><span class="line"></span><br><span class="line"><span class="string">outputs</span> <span class="string">=</span> <span class="string">torch.tensor([[0.1,0.2],</span></span><br><span class="line">                        [<span class="number">0.05</span>,<span class="number">0.4</span>]<span class="string">])</span></span><br><span class="line"><span class="comment"># 1横看 0纵看</span></span><br><span class="line"><span class="string">print(outputs.argmax(1))</span></span><br><span class="line"><span class="comment"># print(outputs.argmax(0))</span></span><br><span class="line"><span class="string">preds</span> <span class="string">=</span> <span class="string">outputs.argmax(1)</span></span><br><span class="line"><span class="string">targets</span> <span class="string">=</span> <span class="string">torch.tensor([0,1])</span></span><br><span class="line"><span class="string">print((preds</span> <span class="string">==</span> <span class="string">targets).sum())</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<ul>
<li>完整代码</li>
</ul>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch.optim</span></span><br><span class="line"><span class="string">import</span> <span class="string">torchvision</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.utils.data</span> <span class="string">import</span> <span class="string">DataLoader</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch</span> <span class="string">import</span> <span class="string">nn</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.utils.tensorboard</span> <span class="string">import</span> <span class="string">SummaryWriter</span></span><br><span class="line"></span><br><span class="line"><span class="string">from</span> <span class="string">model</span> <span class="string">import</span> <span class="string">Xylia</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备数据集</span></span><br><span class="line"><span class="string">train_data</span> <span class="string">=</span> <span class="string">torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;,</span> <span class="string">train=True,</span> <span class="string">download=True,</span></span><br><span class="line">                                          <span class="string">transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"><span class="string">test_data</span> <span class="string">=</span> <span class="string">torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;,</span> <span class="string">train=False,</span> <span class="string">download=True,</span></span><br><span class="line">                                         <span class="string">transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># length 长度</span></span><br><span class="line"><span class="string">train_data_size</span> <span class="string">=</span> <span class="string">len(train_data)</span></span><br><span class="line"><span class="string">test_data_size</span> <span class="string">=</span> <span class="string">len(test_data)</span></span><br><span class="line"><span class="string">print(&quot;训练集的长度为&#123;&#125;&quot;.format(train_data_size))</span></span><br><span class="line"><span class="string">print(&quot;测试集的长度为&#123;&#125;&quot;.format(test_data_size))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用dataloader加载数据集</span></span><br><span class="line"><span class="string">train_dataloader</span> <span class="string">=</span> <span class="string">DataLoader(train_data,</span> <span class="string">batch_size=64)</span></span><br><span class="line"><span class="string">test_dataloader</span> <span class="string">=</span> <span class="string">DataLoader(test_data,</span> <span class="string">batch_size=64)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建神经网络</span></span><br><span class="line"><span class="attr">class Xylia(nn.Module):</span></span><br><span class="line">    <span class="attr">def __init__(self):</span></span><br><span class="line">        <span class="string">super(Xylia,</span> <span class="string">self).__init__()</span></span><br><span class="line">        <span class="string">self.module</span> <span class="string">=</span> <span class="string">nn.Sequential(</span></span><br><span class="line">            <span class="string">nn.Conv2d(3,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Conv2d(32,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Conv2d(32,</span> <span class="number">64</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Flatten(),</span></span><br><span class="line">            <span class="string">nn.Linear(64</span> <span class="string">*</span> <span class="number">4</span> <span class="string">*</span> <span class="number">4</span><span class="string">,</span> <span class="number">64</span><span class="string">),</span></span><br><span class="line">            <span class="string">nn.Linear(64,</span> <span class="number">10</span><span class="string">)</span></span><br><span class="line">        <span class="string">)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">def</span> <span class="string">forward(self,</span> <span class="attr">x):</span></span><br><span class="line">        <span class="string">x</span> <span class="string">=</span> <span class="string">self.module(x)</span></span><br><span class="line">        <span class="string">return</span> <span class="string">x</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建网络模型</span></span><br><span class="line"><span class="string">xylia</span> <span class="string">=</span> <span class="string">Xylia()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建损失函数</span></span><br><span class="line"><span class="string">loss_fn</span> <span class="string">=</span> <span class="string">nn.CrossEntropyLoss()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line"><span class="comment"># 1e-2=1*(10)^(-2)=1</span></span><br><span class="line"><span class="string">leaning_rate</span> <span class="string">=</span> <span class="number">0.01</span></span><br><span class="line"><span class="string">optimizer</span> <span class="string">=</span> <span class="string">torch.optim.SGD(xylia.parameters(),</span> <span class="string">lr=leaning_rate)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练网络的参数</span></span><br><span class="line"><span class="comment"># 记录训练的次数</span></span><br><span class="line"><span class="string">total_train_step</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录测试的次数</span></span><br><span class="line"><span class="string">total_test_step</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 训练轮数</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span> <span class="number">10</span></span><br><span class="line"><span class="string">total_accuracy</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line"><span class="string">writer</span> <span class="string">=</span> <span class="string">SummaryWriter(&#x27;./log_train&#x27;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">for epoch in range(epoch):</span></span><br><span class="line">    <span class="string">print(&quot;----------------------------第&#123;&#125;轮开始--------------------------&quot;.format(epoch))</span></span><br><span class="line">    <span class="comment"># 训练步骤开始</span></span><br><span class="line">    <span class="string">xylia.train()</span></span><br><span class="line">    <span class="attr">for data in train_dataloader:</span></span><br><span class="line">        <span class="string">imgs,targets</span> <span class="string">=</span> <span class="string">data</span></span><br><span class="line">        <span class="string">outputs</span> <span class="string">=</span> <span class="string">xylia(imgs)</span></span><br><span class="line">        <span class="string">loss</span> <span class="string">=</span> <span class="string">loss_fn(outputs,</span> <span class="string">targets)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 优化器优化模型</span></span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        <span class="string">optimizer.zero_grad()</span></span><br><span class="line">        <span class="string">loss.backward()</span></span><br><span class="line">        <span class="string">optimizer.step()</span></span><br><span class="line">        <span class="string">total_train_step</span> <span class="string">+=</span> <span class="number">1</span></span><br><span class="line">        <span class="comment"># print(&quot;训练次数：&#123;&#125;，loss：&#123;&#125;&quot;.format(total_train_step, loss))</span></span><br><span class="line">        <span class="string">if</span> <span class="string">total_train_step</span> <span class="string">%</span> <span class="number">100</span> <span class="string">==</span> <span class="attr">0:</span></span><br><span class="line">            <span class="string">print(&quot;训练次数：&#123;&#125;，loss：&#123;&#125;&quot;.format(total_train_step,</span> <span class="string">loss.item()))</span></span><br><span class="line">            <span class="string">writer.add_scalar(&#x27;train_loss&#x27;,</span> <span class="string">loss.item(),</span> <span class="string">total_train_step)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断模型是否训练好/达到需求，评估</span></span><br><span class="line">    <span class="comment"># 测试</span></span><br><span class="line">    <span class="string">xylia.eval()</span></span><br><span class="line">    <span class="string">total_test_loss</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line">    <span class="comment"># 去掉梯度</span></span><br><span class="line">    <span class="attr">with torch.no_grad():</span></span><br><span class="line">        <span class="attr">for data in test_dataloader:</span></span><br><span class="line">            <span class="string">imgs,targets</span> <span class="string">=</span> <span class="string">data</span></span><br><span class="line">            <span class="string">outputs</span> <span class="string">=</span> <span class="string">xylia(imgs)</span></span><br><span class="line">            <span class="string">loss</span> <span class="string">=</span> <span class="string">loss_fn(outputs,</span> <span class="string">targets)</span></span><br><span class="line">            <span class="string">total_test_loss</span> <span class="string">+=</span> <span class="string">loss.item()</span></span><br><span class="line">            <span class="string">accuracy</span> <span class="string">=</span> <span class="string">(outputs.argmax(1)</span> <span class="string">==</span> <span class="string">targets).sum()</span></span><br><span class="line">            <span class="string">total_accuracy</span> <span class="string">+=</span> <span class="string">accuracy.item()</span></span><br><span class="line">    <span class="string">print(&quot;整体测试集上的loss：&#123;&#125;&quot;.format(total_test_loss))</span></span><br><span class="line">    <span class="string">print(&quot;整体测试集上的正确率：&#123;&#125;&quot;.format(total_accuracy</span> <span class="string">/</span> <span class="string">train_data_size))</span></span><br><span class="line">    <span class="string">writer.add_scalar(&#x27;test_loss&#x27;,</span> <span class="string">total_test_loss,</span> <span class="string">total_test_step)</span></span><br><span class="line">    <span class="string">writer.add_scalar(&#x27;test_accuracy&#x27;,</span> <span class="string">total_accuracy</span> <span class="string">/</span> <span class="string">train_data_size,</span> <span class="string">total_test_step)</span></span><br><span class="line">    <span class="string">total_test_step</span> <span class="string">+=</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="string">torch.save(xylia,&quot;xylia_&#123;&#125;.pth&quot;.format(epoch))</span></span><br><span class="line">    <span class="comment"># torch.save(xylia.state.dict(),&quot;xylia_&#123;&#125;.pth&quot;.format(i))</span></span><br><span class="line">    <span class="string">print(&quot;模型已保存&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">writer.close()</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<h2 id="利用gpu训练"><a class="markdownIt-Anchor" href="#利用gpu训练">#</a> 利用 GPU 训练</h2>
<p>只有网络模型，数据（输入，标注），损失函数有.cuda () 方法</p>
<ul>
<li>.cuda()</li>
</ul>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```gpu</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch.optim</span></span><br><span class="line"><span class="string">import</span> <span class="string">torchvision</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.utils.data</span> <span class="string">import</span> <span class="string">DataLoader</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch</span> <span class="string">import</span> <span class="string">nn</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.utils.tensorboard</span> <span class="string">import</span> <span class="string">SummaryWriter</span></span><br><span class="line"><span class="string">import</span> <span class="string">time</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备数据集</span></span><br><span class="line"><span class="string">train_data</span> <span class="string">=</span> <span class="string">torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;,</span> <span class="string">train=True,</span> <span class="string">download=True,</span></span><br><span class="line">                                          <span class="string">transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"><span class="string">test_data</span> <span class="string">=</span> <span class="string">torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;,</span> <span class="string">train=False,</span> <span class="string">download=True,</span></span><br><span class="line">                                         <span class="string">transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># length 长度</span></span><br><span class="line"><span class="string">train_data_size</span> <span class="string">=</span> <span class="string">len(train_data)</span></span><br><span class="line"><span class="string">test_data_size</span> <span class="string">=</span> <span class="string">len(test_data)</span></span><br><span class="line"><span class="string">print(&quot;训练集的长度为&#123;&#125;&quot;.format(train_data_size))</span></span><br><span class="line"><span class="string">print(&quot;测试集的长度为&#123;&#125;&quot;.format(test_data_size))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用dataloader加载数据集</span></span><br><span class="line"><span class="string">train_dataloader</span> <span class="string">=</span> <span class="string">DataLoader(train_data,</span> <span class="string">batch_size=64)</span></span><br><span class="line"><span class="string">test_dataloader</span> <span class="string">=</span> <span class="string">DataLoader(test_data,</span> <span class="string">batch_size=64)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建神经网络</span></span><br><span class="line"><span class="attr">class Xylia(nn.Module):</span></span><br><span class="line">    <span class="attr">def __init__(self):</span></span><br><span class="line">        <span class="string">super(Xylia,</span> <span class="string">self).__init__()</span></span><br><span class="line">        <span class="string">self.module</span> <span class="string">=</span> <span class="string">nn.Sequential(</span></span><br><span class="line">            <span class="string">nn.Conv2d(3,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Conv2d(32,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Conv2d(32,</span> <span class="number">64</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Flatten(),</span></span><br><span class="line">            <span class="string">nn.Linear(64</span> <span class="string">*</span> <span class="number">4</span> <span class="string">*</span> <span class="number">4</span><span class="string">,</span> <span class="number">64</span><span class="string">),</span></span><br><span class="line">            <span class="string">nn.Linear(64,</span> <span class="number">10</span><span class="string">)</span></span><br><span class="line">        <span class="string">)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">def</span> <span class="string">forward(self,</span> <span class="attr">x):</span></span><br><span class="line">        <span class="string">x</span> <span class="string">=</span> <span class="string">self.module(x)</span></span><br><span class="line">        <span class="string">return</span> <span class="string">x</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建网络模型</span></span><br><span class="line"><span class="string">xylia</span> <span class="string">=</span> <span class="string">Xylia()</span></span><br><span class="line"><span class="attr">if torch.cuda.is_available():</span></span><br><span class="line">    <span class="string">xylia</span> <span class="string">=</span> <span class="string">xylia.cuda()</span>    <span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建损失函数</span></span><br><span class="line"><span class="string">loss_fn</span> <span class="string">=</span> <span class="string">nn.CrossEntropyLoss()</span></span><br><span class="line"><span class="attr">if torch.cuda.is_available():</span></span><br><span class="line">    <span class="string">loss_fn</span> <span class="string">=</span> <span class="string">loss_fn.cuda()</span>     <span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line"><span class="comment"># 1e-2=1*(10)^(-2)=1</span></span><br><span class="line"><span class="string">leaning_rate</span> <span class="string">=</span> <span class="number">0.01</span></span><br><span class="line"><span class="string">optimizer</span> <span class="string">=</span> <span class="string">torch.optim.SGD(xylia.parameters(),</span> <span class="string">lr=leaning_rate)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练网络的参数</span></span><br><span class="line"><span class="comment"># 记录训练的次数</span></span><br><span class="line"><span class="string">total_train_step</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录测试的次数</span></span><br><span class="line"><span class="string">total_test_step</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 训练轮数</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span> <span class="number">10</span></span><br><span class="line"><span class="string">total_accuracy</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line"><span class="string">writer</span> <span class="string">=</span> <span class="string">SummaryWriter(&#x27;./log_train&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">start_time</span> <span class="string">=</span> <span class="string">time.time()</span></span><br><span class="line"></span><br><span class="line"><span class="attr">for epoch in range(epoch):</span></span><br><span class="line">    <span class="string">print(&quot;----------------------------第&#123;&#125;轮开始--------------------------&quot;.format(epoch))</span></span><br><span class="line">    <span class="comment"># 训练步骤开始</span></span><br><span class="line">    <span class="attr">for data in train_dataloader:</span></span><br><span class="line">        <span class="string">imgs,targets</span> <span class="string">=</span> <span class="string">data</span></span><br><span class="line">        <span class="attr">if torch.cuda.is_available():</span></span><br><span class="line">            <span class="string">imgs</span> <span class="string">=</span> <span class="string">imgs.cuda()</span></span><br><span class="line">            <span class="string">targets=</span> <span class="string">targets.cuda()</span></span><br><span class="line">        <span class="string">outputs</span> <span class="string">=</span> <span class="string">xylia(imgs)</span></span><br><span class="line">        <span class="string">loss</span> <span class="string">=</span> <span class="string">loss_fn(outputs,</span> <span class="string">targets)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 优化器优化模型</span></span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        <span class="string">optimizer.zero_grad()</span></span><br><span class="line">        <span class="string">loss.backward()</span></span><br><span class="line">        <span class="string">optimizer.step()</span></span><br><span class="line">        <span class="string">total_train_step</span> <span class="string">+=</span> <span class="number">1</span></span><br><span class="line">        <span class="comment"># print(&quot;训练次数：&#123;&#125;，loss：&#123;&#125;&quot;.format(total_train_step, loss))</span></span><br><span class="line">        <span class="string">if</span> <span class="string">total_train_step</span> <span class="string">%</span> <span class="number">100</span> <span class="string">==</span> <span class="attr">0:</span></span><br><span class="line">            <span class="string">end_time</span> <span class="string">=</span> <span class="string">time.time()</span></span><br><span class="line">            <span class="string">print(end_time</span> <span class="bullet">-</span> <span class="string">start_time)</span></span><br><span class="line">            <span class="string">print(&quot;训练次数：&#123;&#125;，loss：&#123;&#125;&quot;.format(total_train_step,</span> <span class="string">loss.item()))</span></span><br><span class="line">            <span class="string">writer.add_scalar(&#x27;train_loss&#x27;,</span> <span class="string">loss.item(),</span> <span class="string">total_train_step)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断模型是否训练好/达到需求，评估</span></span><br><span class="line">    <span class="comment"># 测试</span></span><br><span class="line">    <span class="string">total_test_loss</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">with torch.no_grad():</span></span><br><span class="line">        <span class="attr">for data in test_dataloader:</span></span><br><span class="line">            <span class="string">imgs,targets</span> <span class="string">=</span> <span class="string">data</span></span><br><span class="line">            <span class="attr">if torch.cuda.is_available():</span></span><br><span class="line">                <span class="string">imgs=</span> <span class="string">imgs.cuda()</span></span><br><span class="line">                <span class="string">targets</span> <span class="string">=</span> <span class="string">targets.cuda()</span></span><br><span class="line">            <span class="string">outputs</span> <span class="string">=</span> <span class="string">xylia(imgs)</span></span><br><span class="line">            <span class="string">loss</span> <span class="string">=</span> <span class="string">loss_fn(outputs,</span> <span class="string">targets)</span></span><br><span class="line">            <span class="string">total_test_loss</span> <span class="string">+=</span> <span class="string">loss.item()</span></span><br><span class="line">            <span class="string">accuracy</span> <span class="string">=</span> <span class="string">(outputs.argmax(1)</span> <span class="string">==</span> <span class="string">targets).sum()</span></span><br><span class="line">            <span class="string">total_accuracy</span> <span class="string">+=</span> <span class="string">accuracy.item()</span></span><br><span class="line">    <span class="string">print(&quot;整体测试集上的loss：&#123;&#125;&quot;.format(total_test_loss))</span></span><br><span class="line">    <span class="string">print(&quot;整体测试集上的正确率：&#123;&#125;&quot;.format(total_accuracy</span> <span class="string">/</span> <span class="string">train_data_size))</span></span><br><span class="line">    <span class="string">writer.add_scalar(&#x27;test_loss&#x27;,</span> <span class="string">total_test_loss,</span> <span class="string">total_test_step)</span></span><br><span class="line">    <span class="string">writer.add_scalar(&#x27;test_accuracy&#x27;,</span> <span class="string">total_accuracy</span> <span class="string">/</span> <span class="string">train_data_size,</span> <span class="string">total_test_step)</span></span><br><span class="line">    <span class="string">total_test_step</span> <span class="string">+=</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="string">torch.save(xylia,&quot;xylia_&#123;&#125;.pth&quot;.format(epoch))</span></span><br><span class="line">    <span class="string">print(&quot;模型已保存&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">writer.close()</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<p><span class="exturl" data-url="aHR0cHM6Ly9jb2xhYi5nb29nbGUv">colab.google</span></p>
<ul>
<li>.to(device)</li>
</ul>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch.optim</span></span><br><span class="line"><span class="string">import</span> <span class="string">torchvision</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.utils.data</span> <span class="string">import</span> <span class="string">DataLoader</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch</span> <span class="string">import</span> <span class="string">nn,</span> <span class="string">device</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch.utils.tensorboard</span> <span class="string">import</span> <span class="string">SummaryWriter</span></span><br><span class="line"><span class="string">import</span> <span class="string">time</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个设备</span></span><br><span class="line"><span class="string">decive</span> <span class="string">=</span> <span class="string">torch.device(&#x27;cpu&#x27;)</span></span><br><span class="line"><span class="comment"># decive = torch.device(&#x27;cuda&#x27;)</span></span><br><span class="line"><span class="comment"># decive = torch.device(&#x27;cuda:0&#x27;)</span></span><br><span class="line"><span class="comment"># decive = torch.device(&#x27;cuda:0&#x27;,if torch.cuda.is_available() else &quot;cpu&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备数据集</span></span><br><span class="line"><span class="string">train_data</span> <span class="string">=</span> <span class="string">torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;,</span> <span class="string">train=True,</span> <span class="string">download=True,</span></span><br><span class="line">                                          <span class="string">transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"><span class="string">test_data</span> <span class="string">=</span> <span class="string">torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;,</span> <span class="string">train=False,</span> <span class="string">download=True,</span></span><br><span class="line">                                         <span class="string">transform=torchvision.transforms.ToTensor())</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># length 长度</span></span><br><span class="line"><span class="string">train_data_size</span> <span class="string">=</span> <span class="string">len(train_data)</span></span><br><span class="line"><span class="string">test_data_size</span> <span class="string">=</span> <span class="string">len(test_data)</span></span><br><span class="line"><span class="string">print(&quot;训练集的长度为&#123;&#125;&quot;.format(train_data_size))</span></span><br><span class="line"><span class="string">print(&quot;测试集的长度为&#123;&#125;&quot;.format(test_data_size))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 利用dataloader加载数据集</span></span><br><span class="line"><span class="string">train_dataloader</span> <span class="string">=</span> <span class="string">DataLoader(train_data,</span> <span class="string">batch_size=64)</span></span><br><span class="line"><span class="string">test_dataloader</span> <span class="string">=</span> <span class="string">DataLoader(test_data,</span> <span class="string">batch_size=64)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建神经网络</span></span><br><span class="line"><span class="attr">class Xylia(nn.Module):</span></span><br><span class="line">    <span class="attr">def __init__(self):</span></span><br><span class="line">        <span class="string">super(Xylia,</span> <span class="string">self).__init__()</span></span><br><span class="line">        <span class="string">self.module</span> <span class="string">=</span> <span class="string">nn.Sequential(</span></span><br><span class="line">            <span class="string">nn.Conv2d(3,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Conv2d(32,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Conv2d(32,</span> <span class="number">64</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Flatten(),</span></span><br><span class="line">            <span class="string">nn.Linear(64</span> <span class="string">*</span> <span class="number">4</span> <span class="string">*</span> <span class="number">4</span><span class="string">,</span> <span class="number">64</span><span class="string">),</span></span><br><span class="line">            <span class="string">nn.Linear(64,</span> <span class="number">10</span><span class="string">)</span></span><br><span class="line">        <span class="string">)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">def</span> <span class="string">forward(self,</span> <span class="attr">x):</span></span><br><span class="line">        <span class="string">x</span> <span class="string">=</span> <span class="string">self.module(x)</span></span><br><span class="line">        <span class="string">return</span> <span class="string">x</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建网络模型</span></span><br><span class="line"><span class="string">xylia</span> <span class="string">=</span> <span class="string">Xylia()</span></span><br><span class="line"><span class="string">xylia.to(device)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建损失函数</span></span><br><span class="line"><span class="string">loss_fn</span> <span class="string">=</span> <span class="string">nn.CrossEntropyLoss()</span></span><br><span class="line"><span class="string">loss_fn</span> <span class="string">=</span> <span class="string">loss_fn.to(device)</span>   <span class="comment">#</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义优化器</span></span><br><span class="line"><span class="comment"># 1e-2=1*(10)^(-2)=1</span></span><br><span class="line"><span class="string">leaning_rate</span> <span class="string">=</span> <span class="number">0.01</span></span><br><span class="line"><span class="string">optimizer</span> <span class="string">=</span> <span class="string">torch.optim.SGD(xylia.parameters(),</span> <span class="string">lr=leaning_rate)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练网络的参数</span></span><br><span class="line"><span class="comment"># 记录训练的次数</span></span><br><span class="line"><span class="string">total_train_step</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 记录测试的次数</span></span><br><span class="line"><span class="string">total_test_step</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># 训练轮数</span></span><br><span class="line"><span class="string">epoch</span> <span class="string">=</span> <span class="number">10</span></span><br><span class="line"><span class="string">total_accuracy</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加tensorboard</span></span><br><span class="line"><span class="string">writer</span> <span class="string">=</span> <span class="string">SummaryWriter(&#x27;./log_train&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">start_time</span> <span class="string">=</span> <span class="string">time.time()</span></span><br><span class="line"></span><br><span class="line"><span class="attr">for epoch in range(epoch):</span></span><br><span class="line">    <span class="string">print(&quot;----------------------------第&#123;&#125;轮开始--------------------------&quot;.format(epoch))</span></span><br><span class="line">    <span class="comment"># 训练步骤开始</span></span><br><span class="line">    <span class="attr">for data in train_dataloader:</span></span><br><span class="line">        <span class="string">imgs,targets</span> <span class="string">=</span> <span class="string">data</span></span><br><span class="line">        <span class="string">imgs</span> <span class="string">=</span> <span class="string">imgs.to(device)</span></span><br><span class="line">        <span class="string">targets</span> <span class="string">=</span> <span class="string">targets.to(device)</span></span><br><span class="line">        <span class="string">outputs</span> <span class="string">=</span> <span class="string">xylia(imgs)</span></span><br><span class="line">        <span class="string">loss</span> <span class="string">=</span> <span class="string">loss_fn(outputs,</span> <span class="string">targets)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 优化器优化模型</span></span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        <span class="string">optimizer.zero_grad()</span></span><br><span class="line">        <span class="string">loss.backward()</span></span><br><span class="line">        <span class="string">optimizer.step()</span></span><br><span class="line">        <span class="string">total_train_step</span> <span class="string">+=</span> <span class="number">1</span></span><br><span class="line">        <span class="comment"># print(&quot;训练次数：&#123;&#125;，loss：&#123;&#125;&quot;.format(total_train_step, loss))</span></span><br><span class="line">        <span class="string">if</span> <span class="string">total_train_step</span> <span class="string">%</span> <span class="number">100</span> <span class="string">==</span> <span class="attr">0:</span></span><br><span class="line">            <span class="string">end_time</span> <span class="string">=</span> <span class="string">time.time()</span></span><br><span class="line">            <span class="string">print(end_time</span> <span class="bullet">-</span> <span class="string">start_time)</span></span><br><span class="line">            <span class="string">print(&quot;训练次数：&#123;&#125;，loss：&#123;&#125;&quot;.format(total_train_step,</span> <span class="string">loss.item()))</span></span><br><span class="line">            <span class="string">writer.add_scalar(&#x27;train_loss&#x27;,</span> <span class="string">loss.item(),</span> <span class="string">total_train_step)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断模型是否训练好/达到需求，评估</span></span><br><span class="line">    <span class="comment"># 测试</span></span><br><span class="line">    <span class="string">total_test_loss</span> <span class="string">=</span> <span class="number">0</span></span><br><span class="line">    <span class="attr">with torch.no_grad():</span></span><br><span class="line">        <span class="attr">for data in test_dataloader:</span></span><br><span class="line">            <span class="string">imgs,targets</span> <span class="string">=</span> <span class="string">data</span></span><br><span class="line">            <span class="string">imgs</span> <span class="string">=</span> <span class="string">imgs.to(device)</span></span><br><span class="line">            <span class="string">targets</span> <span class="string">=</span> <span class="string">targets.to(device)</span></span><br><span class="line">            <span class="string">outputs</span> <span class="string">=</span> <span class="string">xylia(imgs)</span></span><br><span class="line">            <span class="string">loss</span> <span class="string">=</span> <span class="string">loss_fn(outputs,</span> <span class="string">targets)</span></span><br><span class="line">            <span class="string">total_test_loss</span> <span class="string">+=</span> <span class="string">loss.item()</span></span><br><span class="line">            <span class="string">accuracy</span> <span class="string">=</span> <span class="string">(outputs.argmax(1)</span> <span class="string">==</span> <span class="string">targets).sum()</span></span><br><span class="line">            <span class="string">total_accuracy</span> <span class="string">+=</span> <span class="string">accuracy.item()</span></span><br><span class="line">    <span class="string">print(&quot;整体测试集上的loss：&#123;&#125;&quot;.format(total_test_loss))</span></span><br><span class="line">    <span class="string">print(&quot;整体测试集上的正确率：&#123;&#125;&quot;.format(total_accuracy</span> <span class="string">/</span> <span class="string">train_data_size))</span></span><br><span class="line">    <span class="string">writer.add_scalar(&#x27;test_loss&#x27;,</span> <span class="string">total_test_loss,</span> <span class="string">total_test_step)</span></span><br><span class="line">    <span class="string">writer.add_scalar(&#x27;test_accuracy&#x27;,</span> <span class="string">total_accuracy</span> <span class="string">/</span> <span class="string">train_data_size,</span> <span class="string">total_test_step)</span></span><br><span class="line">    <span class="string">total_test_step</span> <span class="string">+=</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="string">torch.save(xylia,&quot;xylia_&#123;&#125;.pth&quot;.format(epoch))</span></span><br><span class="line">    <span class="string">print(&quot;模型已保存&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="string">writer.close()</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<h2 id="完整的模型验证测试demo套路"><a class="markdownIt-Anchor" href="#完整的模型验证测试demo套路">#</a> 完整的模型验证 (测试，demo) 套路</h2>
<p>利用已经训练好的模型，然后给它提供一个输入</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">```</span></span><br><span class="line"><span class="string">from</span> <span class="string">PIL</span> <span class="string">import</span> <span class="string">Image</span></span><br><span class="line"><span class="string">import</span> <span class="string">torchvision</span></span><br><span class="line"><span class="string">from</span> <span class="string">torch</span> <span class="string">import</span> <span class="string">nn</span></span><br><span class="line"><span class="string">import</span> <span class="string">torch</span></span><br><span class="line"><span class="string">device</span> <span class="string">=</span> <span class="string">torch.device(&quot;cuda&quot;</span> <span class="string">if</span> <span class="string">torch.cuda.is_available()</span> <span class="string">else</span> <span class="string">&quot;cpu&quot;</span><span class="string">)</span></span><br><span class="line"></span><br><span class="line"><span class="string">img_path</span> <span class="string">=</span> <span class="string">&quot;./imgs/dog.jpg&quot;</span></span><br><span class="line"><span class="string">image</span> <span class="string">=</span> <span class="string">Image.open(img_path)</span></span><br><span class="line"><span class="string">print(image)</span></span><br><span class="line"></span><br><span class="line"><span class="string">transforms</span> <span class="string">=</span> <span class="string">torchvision.transforms.Compose([torchvision.transforms.Resize((32,32)),</span></span><br><span class="line">                                            <span class="string">torchvision.transforms.ToTensor()])</span></span><br><span class="line"></span><br><span class="line"><span class="string">image</span> <span class="string">=</span> <span class="string">transforms(image)</span></span><br><span class="line"><span class="string">print(image.shape)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="attr">class Xylia(nn.Module):</span></span><br><span class="line">    <span class="attr">def __init__(self):</span></span><br><span class="line">        <span class="string">super(Xylia,</span> <span class="string">self).__init__()</span></span><br><span class="line">        <span class="string">self.module</span> <span class="string">=</span> <span class="string">nn.Sequential(</span></span><br><span class="line">            <span class="string">nn.Conv2d(3,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Conv2d(32,</span> <span class="number">32</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Conv2d(32,</span> <span class="number">64</span><span class="string">,</span> <span class="string">kernel_size=5,</span> <span class="string">stride=1,</span> <span class="string">padding=2),</span></span><br><span class="line">            <span class="string">nn.MaxPool2d(kernel_size=2),</span></span><br><span class="line">            <span class="string">nn.Flatten(),</span></span><br><span class="line">            <span class="string">nn.Linear(64</span> <span class="string">*</span> <span class="number">4</span> <span class="string">*</span> <span class="number">4</span><span class="string">,</span> <span class="number">64</span><span class="string">),</span></span><br><span class="line">            <span class="string">nn.Linear(64,</span> <span class="number">10</span><span class="string">)</span></span><br><span class="line">        <span class="string">)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">def</span> <span class="string">forward(self,</span> <span class="attr">x):</span></span><br><span class="line">        <span class="string">x</span> <span class="string">=</span> <span class="string">self.module(x)</span></span><br><span class="line">        <span class="string">return</span> <span class="string">x</span></span><br><span class="line"></span><br><span class="line"><span class="string">model</span> <span class="string">=</span> <span class="string">torch.load(&quot;xylia_9.pth&quot;,weights_only=False)</span></span><br><span class="line"><span class="string">print(model)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将模型和输入数据移动到同一设备</span></span><br><span class="line"><span class="string">model</span> <span class="string">=</span> <span class="string">model.to(device)</span></span><br><span class="line"></span><br><span class="line"><span class="string">image</span> <span class="string">=</span> <span class="string">torch.reshape(image,(1,3,32,32))</span></span><br><span class="line"><span class="string">image</span> <span class="string">=</span> <span class="string">image.to(device)</span></span><br><span class="line"><span class="string">model.eval()</span></span><br><span class="line"><span class="attr">with torch.no_grad():</span></span><br><span class="line">    <span class="string">output</span> <span class="string">=</span> <span class="string">model(image)</span></span><br><span class="line"><span class="string">print(output)</span></span><br><span class="line"><span class="string">print(output.argmax(dim=1))</span></span><br><span class="line"><span class="string">```</span></span><br></pre></td></tr></table></figure>
<p><img data-src="https://cdn.jsdelivr.net/gh/Mia-Xylia/Mia-Xylia-pictures@master/img/09612e111516390645e8f5710aadede.png" alt="img"></p>

      <div class="tags">
          <a href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag"><i class="ic i-tag"></i> 笔记</a>
          <a href="/tags/pytorch%E5%9F%BA%E7%A1%80/" rel="tag"><i class="ic i-tag"></i> pytorch基础</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">更新于</span>
    <time title="修改时间：2025-03-27 14:27:24" itemprop="dateModified" datetime="2025-03-27T14:27:24+08:00">2025-03-27</time>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> 赞赏</button>
  <p>请我喝[茶]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="https://fastly.jsdelivr.net/gh/Mia-Xylia/Mia-Xylia.github.io@latest/images/wechatpay.png" alt="Xylia 微信支付">
        <p>微信支付</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>本文作者： </strong>Xylia <i class="ic i-at"><em>@</em></i>
  </li>
  <li class="link">
    <strong>本文链接：</strong>
    <a href="http://example.com/2025/03/26/computer-science/python/pytorch3/" title="笔记：PyTorch(3)">http://example.com/2025/03/26/computer-science/python/pytorch3/</a>
  </li>
  <li class="license">
    <strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC96aC1DTg=="><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2025/03/25/computer-science/python/pytorch1/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;fastly.jsdelivr.net&#x2F;gh&#x2F;Mia-Xylia&#x2F;Mia-Xylia.github.io@latest&#x2F;assets&#x2F;wallpaper-2572384.jpg" title="笔记：PyTorch(1)">
  <span class="type">上一篇</span>
  <span class="category"><i class="ic i-flag"></i> Python</span>
  <h3>笔记：PyTorch(1)</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/2025/03/26/computer-science/python/pytorch2/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;fastly.jsdelivr.net&#x2F;gh&#x2F;Mia-Xylia&#x2F;Mia-Xylia.github.io@latest&#x2F;assets&#x2F;wallpaper-2572384.jpg" title="笔记：PyTorch(2)">
  <span class="type">下一篇</span>
  <span class="category"><i class="ic i-flag"></i> Python</span>
  <h3>笔记：PyTorch(2)</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="文章目录">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#loss-functions"><span class="toc-number">1.</span> <span class="toc-text"> Loss Functions</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">2.</span> <span class="toc-text"> 优化器</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text"> 网络模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%B0%E6%9C%89%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8F%8A%E4%BF%AE%E6%94%B9"><span class="toc-number">3.1.</span> <span class="toc-text"> 现有网络模型的使用及修改</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98%E4%B8%8E%E8%AF%BB%E5%8F%96"><span class="toc-number">3.2.</span> <span class="toc-text"> 网络模型的保存与读取</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%A5%97%E8%B7%AF"><span class="toc-number">3.3.</span> <span class="toc-text"> 完整的模型训练套路</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A9%E7%94%A8gpu%E8%AE%AD%E7%BB%83"><span class="toc-number">3.4.</span> <span class="toc-text"> 利用 GPU 训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E6%A8%A1%E5%9E%8B%E9%AA%8C%E8%AF%81%E6%B5%8B%E8%AF%95demo%E5%A5%97%E8%B7%AF"><span class="toc-number">3.5.</span> <span class="toc-text"> 完整的模型验证 (测试，demo) 套路</span></a></li></ol></li></ol>
      </div>
      <div class="related panel pjax" data-title="系列文章">
        <ul>
          <li><a href="/2025/03/23/computer-science/python/pytorch0/" rel="bookmark" title="笔记：PyTorch(0)">笔记：PyTorch(0)</a></li><li><a href="/2025/03/25/computer-science/python/pytorch1/" rel="bookmark" title="笔记：PyTorch(1)">笔记：PyTorch(1)</a></li><li><a href="/2025/03/26/computer-science/python/pytorch2/" rel="bookmark" title="笔记：PyTorch(2)">笔记：PyTorch(2)</a></li><li class="active"><a href="/2025/03/26/computer-science/python/pytorch3/" rel="bookmark" title="笔记：PyTorch(3)">笔记：PyTorch(3)</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="站点概览">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="Xylia"
      data-src="https://fastly.jsdelivr.net/gh/Mia-Xylia/Mia-Xylia.github.io@latest/images/avatar.jpg">
  <p class="name" itemprop="name">Xylia</p>
  <div class="description" itemprop="description"></div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">8</span>
        <span class="name">文章</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">4</span>
        <span class="name">分类</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">4</span>
        <span class="name">标签</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL01pYS1YeWxpYQ==" title="https:&#x2F;&#x2F;github.com&#x2F;Mia-Xylia"><i class="ic i-github"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>首页</a>
  </li>

    
  <li class="item">
    <a href="/about/" rel="section"><i class="ic i-user"></i>关于</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a>
  </li>

  </ul>
        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>链环</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a>
  </li>

        
  <li class="item">
    <a href="/links/" rel="section"><i class="ic i-magic"></i>链接</a>
  </li>

  </ul>

</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/2025/03/25/computer-science/python/pytorch1/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/2025/03/26/computer-science/python/pytorch2/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>随机文章</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a>
<i class="ic i-angle-right"></i>
<a href="/categories/computer-science/python/" title="分类于 Python">Python</a>
</div>

    <span><a href="/2025/03/26/computer-science/python/pytorch2/" title="笔记：PyTorch(2)">笔记：PyTorch(2)</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a>
<i class="ic i-angle-right"></i>
<a href="/categories/computer-science/python/" title="分类于 Python">Python</a>
</div>

    <span><a href="/2025/03/26/computer-science/python/pytorch3/" title="笔记：PyTorch(3)">笔记：PyTorch(3)</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a>
<i class="ic i-angle-right"></i>
<a href="/categories/computer-science/crawler/" title="分类于 爬虫">爬虫</a>
</div>

    <span><a href="/2025/03/23/computer-science/crawler/1/" title="爬取今日菜价：2025.3.23云南蔬菜市场综合菜价">爬取今日菜价：2025.3.23云南蔬菜市场综合菜价</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a>
<i class="ic i-angle-right"></i>
<a href="/categories/computer-science/python/" title="分类于 Python">Python</a>
</div>

    <span><a href="/2025/03/25/computer-science/python/pytorch1/" title="笔记：PyTorch(1)">笔记：PyTorch(1)</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a>
<i class="ic i-angle-right"></i>
<a href="/categories/computer-science/java/" title="分类于 java">java</a>
</div>

    <span><a href="/2025/03/26/computer-science/java/%E5%9F%BA%E7%A1%801/" title="笔记：java（0）">笔记：java（0）</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
</div>

    <span><a href="/2025/03/27/computer-science/java/%E5%9F%BA%E7%A1%803/" title="未命名">未命名</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a>
<i class="ic i-angle-right"></i>
<a href="/categories/computer-science/python/" title="分类于 Python">Python</a>
</div>

    <span><a href="/2025/03/23/computer-science/python/pytorch0/" title="笔记：PyTorch(0)">笔记：PyTorch(0)</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/computer-science/" title="分类于 计算机科学">计算机科学</a>
<i class="ic i-angle-right"></i>
<a href="/categories/computer-science/java/" title="分类于 java">java</a>
</div>

    <span><a href="/2025/03/26/computer-science/java/%E5%9F%BA%E7%A1%802/" title="笔记：java（1）">笔记：java（1）</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>最新评论</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Xylia @ 鱼塘</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="站点总字数">38k 字</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="站点阅读时长">34 分钟</span>
  </div>
  <div class="powered-by">
    基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2025/03/26/computer-science/python/pytorch3/',
    favicon: {
      show: "（●´3｀●）やれやれだぜ",
      hide: "(´Д｀)大変だ！"
    },
    search : {
      placeholder: "文章搜索",
      empty: "关于 「 ${query} 」，什么也没搜到",
      stats: "${time} ms 内找到 ${hits} 条结果"
    },
    valine: true,fancybox: true,
    copyright: '复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//fastly.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="https://fastly.jsdelivr.net/gh/Mia-Xylia/Mia-Xylia.github.io@latest/js/app.js?v=0.2.5"></script>




</body>
</html>
